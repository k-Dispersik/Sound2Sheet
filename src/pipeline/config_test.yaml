# Sound2Sheet TEST Pipeline Configuration
# Quick test to validate all components

# Dataset Generation (SMALL for testing)
dataset:
  samples: 10  # Very small for quick test
  complexity: "medium"
  min_notes: 5
  max_notes: 20
  min_duration: 3.0
  max_duration: 10.0
  key_signatures: ["C", "G"]  # Only 2 keys
  time_signatures: ["4/4"]  # Only one time signature
  output_dir: "data/datasets/test_run"
  synthesize_audio: true
  soundfont_path: null

# Audio Processing
audio:
  sample_rate: 16000
  n_fft: 1024
  hop_length: 320
  n_mels: 128
  f_min: 0.0
  f_max: 8000.0
  normalize: true
  pre_emphasis: 0.97
  augmentation:
    enabled: true
    noise_type: "random"  # Randomly choose from pool
    noise_types_pool: ["ambient", "white", "pink"]  # Only these 3 types
    noise_level: 0.01  # Slightly higher for testing visibility
    pitch_shift_range: [-2, 2]
    time_stretch_range: [0.9, 1.1]

# Model Architecture
model:
  encoder_name: "MIT/ast-finetuned-audioset-10-10-0.4593"
  freeze_encoder: true
  hidden_size: 768
  num_decoder_layers: 6
  num_attention_heads: 8
  dropout: 0.1
  max_sequence_length: 512
  vocab_size: 388
  device: "cuda"

# Training Configuration (MINIMAL for testing)
training:
  batch_size: 4  # Small batch
  num_epochs: 3  # Just 3 epochs
  learning_rate: 0.0001
  weight_decay: 0.01
  warmup_steps: 10  # Minimal warmup
  max_grad_norm: 1.0
  use_mixed_precision: true
  gradient_accumulation_steps: 1
  num_workers: 2  # Fewer workers
  
  lr_schedule: "cosine"
  
  early_stopping_patience: 5
  early_stopping_min_delta: 0.001
  
  checkpoint_dir: "models/checkpoints"
  save_every_n_epochs: 2
  keep_last_n_checkpoints: 2
  
  log_dir: "logs"
  log_every_n_steps: 5  # More frequent logging
  eval_every_n_epochs: 1

# Inference Configuration
inference:
  strategy: "greedy"  # Faster for testing
  max_length: 512
  num_beams: 3
  temperature: 1.0
  top_k: 50
  top_p: 0.95
  repetition_penalty: 1.2

# Evaluation Configuration
evaluation:
  enabled: false  # Skip for quick test
  onset_tolerance: 0.05
  offset_tolerance: 0.05
  pitch_tolerance: 0
  min_duration: 0.1
  max_duration: null
  
  visualizations:
    enabled: true
    output_dir: "results/visualizations"
    plot_types: ["dashboard"]
  
  reports:
    enabled: true
    output_dir: "results/reports"
    formats: ["json", "csv"]

# Output paths
output:
  model_dir: "models/trained"
  results_dir: "results"
  final_model_name: "sound2sheet_test_model.pt"
