{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55768041",
   "metadata": {},
   "source": [
    "# Initial Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "887b01dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# midiutil\n",
    "# Check GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6123b613",
   "metadata": {},
   "source": [
    "### Install Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aabc646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/k-Dispersik/Sound2Sheet.git\n",
    "%cd Sound2Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417e291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install system dependencies\n",
    "!apt-get update -qq\n",
    "!apt-get install -y -qq fluidsynth fluid-soundfont-gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfce94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Python packages\n",
    "!pip install -r requirements.txt\n",
    "print(\"Installation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "026dcc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/volodymyr/VS code/My_projecs/Pythons/Sound2Sheet/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful\n"
     ]
    }
   ],
   "source": [
    "# Verify imports\n",
    "from src.model import Sound2SheetModel, Trainer, create_dataloaders\n",
    "\n",
    "print(\"All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abe96b6",
   "metadata": {},
   "source": [
    "# Training Pipeline\n",
    "\n",
    "Pipeline for training Sound2Sheet model with synthetic piano data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e3db7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline functions imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import pipeline functions\n",
    "from run_pipeline import (\n",
    "    read_config,\n",
    "    generate_synthetic_data,\n",
    "    create_model_config,\n",
    "    create_loader,\n",
    "    create_model,\n",
    "    run_train\n",
    ")\n",
    "\n",
    "print(\"Pipeline functions imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f467adfa",
   "metadata": {},
   "source": [
    "## Load Configuration\n",
    "\n",
    "Read experiment settings from `config.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "531c8ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: data/sound2sheet_experiment_01\n",
      "Dataset samples: 10\n",
      "Epochs: 3\n",
      "Batch size: 32\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "config = read_config(\"config.json\")\n",
    "\n",
    "print(f\"Experiment: {config['experiment_name']}\")\n",
    "print(f\"Dataset samples: {config['dataset']['total_samples']}\")\n",
    "print(f\"Epochs: {config['training']['num_epochs']}\")\n",
    "print(f\"Batch size: {config['training']['batch_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dd41e9",
   "metadata": {},
   "source": [
    "## Step 1: Generate Synthetic Data\n",
    "\n",
    "Create training dataset with MIDI and audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adee3569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train: 100%|██████████| 7/7 [00:02<00:00,  3.07sample/s, complexity=int, tempo=67] \n",
      "Generating train: 100%|██████████| 7/7 [00:02<00:00,  3.07sample/s, complexity=int, tempo=67]\n",
      "Generating val: 100%|██████████| 1/1 [00:00<00:00,  4.68sample/s, complexity=beg, tempo=94]\n",
      "Generating val: 100%|██████████| 1/1 [00:00<00:00,  4.68sample/s, complexity=beg, tempo=94]\n",
      "Generating test: 100%|██████████| 2/2 [00:00<00:00,  5.55sample/s, complexity=beg, tempo=172]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset generated: data/sound2sheet_experiment_01\n",
      "CPU times: user 214 ms, sys: 53.9 ms, total: 268 ms\n",
      "Wall time: 2.86 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data = generate_synthetic_data(\n",
    "    total_samples=config[\"dataset\"][\"total_samples\"],\n",
    "    complexity_distribution=config[\"dataset\"][\"complexity_distribution\"],\n",
    "    output_dir=config[\"experiment_name\"]\n",
    ")\n",
    "\n",
    "print(f\"✓ Dataset generated: {config['experiment_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f406e36e",
   "metadata": {},
   "source": [
    "## Step 2: Create DataLoaders\n",
    "\n",
    "Prepare train/validation/test dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "308b94c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Train batches: 1\n",
      "✓ Val batches: 1\n",
      "✓ Test batches: 1\n"
     ]
    }
   ],
   "source": [
    "# Create model config\n",
    "model_config = create_model_config(config, device)\n",
    "\n",
    "# Create dataloaders\n",
    "loaders, training_config = create_loader(config, model_config)\n",
    "train_loader, val_loader, test_loader = loaders\n",
    "\n",
    "print(f\"✓ Train batches: {len(train_loader)}\")\n",
    "print(f\"✓ Val batches: {len(val_loader)}\")\n",
    "print(f\"✓ Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2147b9",
   "metadata": {},
   "source": [
    "## Step 3: Create Model\n",
    "\n",
    "Initialize Sound2Sheet model (AST encoder + Piano Roll Classifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "949ebdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model created on cpu\n",
      "  Total parameters: 88,047,704\n",
      "  Trainable parameters: 1,860,440\n"
     ]
    }
   ],
   "source": [
    "model = create_model(config, device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"✓ Model created on {device}\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b46584",
   "metadata": {},
   "source": [
    "## Step 4: Train Model\n",
    "\n",
    "Run training loop with mixed precision and checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87b95a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:38<00:00, 38.46s/it, loss=0.72]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation: 100%|██████████| 1/1 [00:01<00:00,  1.98s/it]\n",
      "\n",
      "Epoch 2: 100%|██████████| 1/1 [00:37<00:00, 37.59s/it, loss=0.72]\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Validation: 100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n",
      "Validation: 100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n",
      "Epoch 3: 100%|██████████| 1/1 [00:38<00:00, 38.51s/it, loss=0.72]\n",
      "Epoch 3: 100%|██████████| 1/1 [00:38<00:00, 38.51s/it, loss=0.72]\n",
      "Validation: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Training complete!\n",
      "  Best model saved to: data/sound2sheet_experiment_01/checkpoints\n",
      "CPU times: user 9min 57s, sys: 5.8 s, total: 10min 3s\n",
      "Wall time: 2min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trainer = run_train(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    model_config=model_config,\n",
    "    training_config=training_config\n",
    ")\n",
    "\n",
    "print(\"✓ Training complete!\")\n",
    "print(f\"  Best model saved to: {training_config.checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4396cb9e",
   "metadata": {},
   "source": [
    "## Training Metrics\n",
    "\n",
    "View training history and loss curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86d4a56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training history\n",
    "if hasattr(trainer, 'history'):\n",
    "    history = trainer.history\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0].plot(history['train_loss'], label='Train Loss')\n",
    "    axes[0].plot(history['val_loss'], label='Val Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Accuracy\n",
    "    if 'train_acc' in history:\n",
    "        axes[1].plot(history['train_acc'], label='Train Acc')\n",
    "        axes[1].plot(history['val_acc'], label='Val Acc')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('Accuracy')\n",
    "        axes[1].set_title('Training Accuracy')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Best epoch: {history['best_epoch']}\")\n",
    "    print(f\"Best val loss: {history['best_val_loss']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
