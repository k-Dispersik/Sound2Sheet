{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18c64483",
   "metadata": {},
   "source": [
    "# Sound2Sheet Training Pipeline\n",
    "\n",
    "Complete training pipeline for audio-to-sheet-music transcription model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a30caa",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7593ecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2549346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/k-Dispersik/Sound2Sheet.git\n",
    "%cd Sound2Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d058725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install system dependencies\n",
    "!apt-get update -qq\n",
    "!apt-get install -y -qq fluidsynth fluid-soundfont-gm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd8439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Python packages\n",
    "!pip install -q torch torchaudio transformers librosa numpy pandas tqdm pyyaml \\\n",
    "    pretty_midi music21 matplotlib mido midi2audio accelerate scipy scikit-learn\n",
    "\n",
    "print(\"Installation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8cc902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify imports\n",
    "from src.model import Sound2SheetModel, Trainer, create_dataloaders\n",
    "\n",
    "print(\"All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a6f019",
   "metadata": {},
   "source": [
    "## Step 2: Generate Dataset\n",
    "\n",
    "Configure and generate synthetic training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9171202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configuration\n",
    "SAMPLES = 10_000          # Total samples (train + val + test)\n",
    "COMPLEXITY_DIST = \"beginner:0.4,intermediate:0.5,advanced:0.1\"  # Complexity distribution\n",
    "EPOCHS = 50           # Training epochs\n",
    "BATCH_SIZE = 64         # Batch size\n",
    "LEARNING_RATE = 1e-5    # Learning rate\n",
    "EXPERIMENT_NAME = \"Sound2Sheet_Experiment\"\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Samples: {SAMPLES}\")\n",
    "print(f\"  Complexity: {COMPLEXITY_DIST}\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9eb523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "!python -m src.dataset.cli generate \\\n",
    "    --samples {SAMPLES} \\\n",
    "    --complexity-dist {COMPLEXITY_DIST} \\\n",
    "    --name {EXPERIMENT_NAME} \\\n",
    "    --output-dir data/{EXPERIMENT_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3267f6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset path (no versioned subdirectory anymore)\n",
    "dataset_path = f\"data/{EXPERIMENT_NAME}\"\n",
    "print(f\"Dataset: {dataset_path}\")\n",
    "\n",
    "# Show dataset info\n",
    "!python -m src.dataset.cli info {dataset_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f4168f",
   "metadata": {},
   "source": [
    "## Step 3: Configure Model\n",
    "\n",
    "Set up model architecture and training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd49cc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.config import ModelConfig, TrainingConfig, DataConfig\n",
    "from pathlib import Path\n",
    "\n",
    "# Use dataset_path from previous step\n",
    "# dataset_path was already set in the verification step above\n",
    "\n",
    "# Model configuration\n",
    "model_config = ModelConfig(\n",
    "    vocab_size=128,\n",
    "    hidden_size=256,\n",
    "    num_decoder_layers=4,\n",
    "    num_attention_heads=8,\n",
    "    dropout=0.1,\n",
    "    max_sequence_length=512,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Training configuration\n",
    "training_config = TrainingConfig(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_epochs=EPOCHS,\n",
    "    optimizer='adamw',\n",
    "    scheduler='cosine',\n",
    "    use_mixed_precision=True,\n",
    "    max_grad_norm=4.0,\n",
    "    gradient_accumulation_steps=1,\n",
    "    checkpoint_dir=f'data/{EXPERIMENT_NAME}/checkpoints',\n",
    "    log_dir=f'data/{EXPERIMENT_NAME}/logs',\n",
    "    save_every_n_epochs=10,\n",
    "    early_stopping_patience=10\n",
    ")\n",
    "\n",
    "# Data configuration\n",
    "data_config = DataConfig(\n",
    "    sample_rate=16000,\n",
    "    n_mels=128,\n",
    "    dataset_dir=Path(dataset_path)\n",
    ")\n",
    "\n",
    "print(\"Model configuration:\")\n",
    "print(f\"  Hidden size: {model_config.hidden_size}\")\n",
    "print(f\"  Decoder layers: {model_config.num_decoder_layers}\")\n",
    "print(f\"  Attention heads: {model_config.num_attention_heads}\")\n",
    "print(f\"\\nTraining configuration:\")\n",
    "print(f\"  Learning rate: {training_config.learning_rate}\")\n",
    "print(f\"  Batch size: {training_config.batch_size}\")\n",
    "print(f\"  Epochs: {training_config.num_epochs}\")\n",
    "print(f\"  Mixed precision: {training_config.use_mixed_precision}\")\n",
    "print(f\"  Gradient accumulation: {training_config.gradient_accumulation_steps}\")\n",
    "print(f\"\\nDataset path: {dataset_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bc58bc",
   "metadata": {},
   "source": [
    "## Step 4: Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca29fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_loader, val_loader, test_loader = create_dataloaders(\n",
    "    data_config, model_config, training_config\n",
    ")\n",
    "\n",
    "print(f\"Dataset splits:\")\n",
    "print(f\"  Train samples: {len(train_loader.dataset)}\")\n",
    "print(f\"  Val samples: {len(val_loader.dataset)}\")\n",
    "print(f\"  Test samples: {len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef1d7c9",
   "metadata": {},
   "source": [
    "## Step 5: Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4a9a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = Sound2SheetModel(model_config, freeze_encoder=True)\n",
    "\n",
    "# Count parameters\n",
    "params = model.count_parameters()\n",
    "print(f\"Model parameters:\")\n",
    "print(f\"  Total: {params['total']:,}\")\n",
    "print(f\"  Trainable: {params['trainable']:,}\")\n",
    "print(f\"  Frozen: {params['frozen']:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bca7cf",
   "metadata": {},
   "source": [
    "## Step 6: Train Model\n",
    "\n",
    "Start training with progress tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7557ea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    model_config=model_config,\n",
    "    training_config=training_config\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41b8e5f",
   "metadata": {},
   "source": [
    "## Step 7: Visualize Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774e7e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Load training history\n",
    "history_file = Path(f'data/{EXPERIMENT_NAME}/logs/training_history.json')\n",
    "if history_file.exists():\n",
    "    with open(history_file, 'r') as f:\n",
    "        history = json.load(f)\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    fig = plt.figure(figsize=(18, 10))\n",
    "    \n",
    "    # 1. Loss curves (top left)\n",
    "    ax1 = plt.subplot(2, 3, 1)\n",
    "    epochs = range(1, len(history['train_losses']) + 1)\n",
    "    ax1.plot(epochs, history['train_losses'], 'b-', label='Train Loss', linewidth=2, marker='o', markersize=3)\n",
    "    ax1.plot(epochs, history['val_losses'], 'r-', label='Val Loss', linewidth=2, marker='s', markersize=3)\n",
    "    ax1.set_xlabel('Epoch', fontsize=12)\n",
    "    ax1.set_ylabel('Loss', fontsize=12)\n",
    "    ax1.set_title('Training & Validation Loss', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(fontsize=10)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Mark best epoch\n",
    "    best_epoch = history['val_losses'].index(min(history['val_losses']))\n",
    "    ax1.axvline(x=best_epoch + 1, color='green', linestyle='--', alpha=0.7, label=f'Best: Epoch {best_epoch + 1}')\n",
    "    ax1.scatter([best_epoch + 1], [history['val_losses'][best_epoch]], color='green', s=100, zorder=5, marker='*')\n",
    "    \n",
    "    # 2. Accuracy (top middle)\n",
    "    ax2 = plt.subplot(2, 3, 2)\n",
    "    ax2.plot(epochs, [acc * 100 for acc in history['val_accuracy']], 'g-', label='Val Accuracy', linewidth=2, marker='d', markersize=3)\n",
    "    ax2.set_xlabel('Epoch', fontsize=12)\n",
    "    ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "    ax2.set_title('Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(fontsize=10)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.scatter([best_epoch + 1], [history['val_accuracy'][best_epoch] * 100], color='green', s=100, zorder=5, marker='*')\n",
    "    \n",
    "    # 3. Learning Rate (top right)\n",
    "    ax3 = plt.subplot(2, 3, 3)\n",
    "    if 'learning_rate' in history:\n",
    "        ax3.plot(epochs, history['learning_rate'], 'm-', linewidth=2)\n",
    "        ax3.set_xlabel('Epoch', fontsize=12)\n",
    "        ax3.set_ylabel('Learning Rate', fontsize=12)\n",
    "        ax3.set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "        ax3.set_yscale('log')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        ax3.text(0.5, 0.5, 'LR data not available', ha='center', va='center', fontsize=12)\n",
    "        ax3.set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # 4. Loss difference (bottom left)\n",
    "    ax4 = plt.subplot(2, 3, 4)\n",
    "    loss_diff = [abs(t - v) for t, v in zip(history['train_losses'], history['val_losses'])]\n",
    "    ax4.plot(epochs, loss_diff, 'orange', linewidth=2, marker='x', markersize=4)\n",
    "    ax4.set_xlabel('Epoch', fontsize=12)\n",
    "    ax4.set_ylabel('|Train Loss - Val Loss|', fontsize=12)\n",
    "    ax4.set_title('Overfitting Indicator', fontsize=14, fontweight='bold')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.axhline(y=0.1, color='red', linestyle='--', alpha=0.5, label='Threshold: 0.1')\n",
    "    ax4.legend(fontsize=10)\n",
    "    \n",
    "    # 5. Loss improvement (bottom middle)\n",
    "    ax5 = plt.subplot(2, 3, 5)\n",
    "    val_loss_improvement = [history['val_losses'][0] - v for v in history['val_losses']]\n",
    "    ax5.plot(epochs, val_loss_improvement, 'purple', linewidth=2, marker='o', markersize=3)\n",
    "    ax5.set_xlabel('Epoch', fontsize=12)\n",
    "    ax5.set_ylabel('Improvement from Initial', fontsize=12)\n",
    "    ax5.set_title('Val Loss Improvement', fontsize=14, fontweight='bold')\n",
    "    ax5.grid(True, alpha=0.3)\n",
    "    ax5.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    \n",
    "    # 6. Statistics table (bottom right)\n",
    "    ax6 = plt.subplot(2, 3, 6)\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    stats_data = [\n",
    "        ['Metric', 'Value'],\n",
    "        ['Total Epochs', f\"{len(epochs)}\"],\n",
    "        ['Best Epoch', f\"{best_epoch + 1}\"],\n",
    "        ['Best Val Loss', f\"{min(history['val_losses']):.4f}\"],\n",
    "        ['Best Val Accuracy', f\"{max(history['val_accuracy']):.2%}\"],\n",
    "        ['Final Train Loss', f\"{history['train_losses'][-1]:.4f}\"],\n",
    "        ['Final Val Loss', f\"{history['val_losses'][-1]:.4f}\"],\n",
    "        ['Improvement', f\"{(history['val_losses'][0] - min(history['val_losses'])):.4f}\"],\n",
    "    ]\n",
    "    \n",
    "    table = ax6.table(cellText=stats_data, cellLoc='left', loc='center',\n",
    "                      colWidths=[0.6, 0.4], bbox=[0, 0, 1, 1])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1, 2)\n",
    "    \n",
    "    # Style header row\n",
    "    for i in range(2):\n",
    "        table[(0, i)].set_facecolor('#4CAF50')\n",
    "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "    \n",
    "    # Alternate row colors\n",
    "    for i in range(1, len(stats_data)):\n",
    "        for j in range(2):\n",
    "            if i % 2 == 0:\n",
    "                table[(i, j)].set_facecolor('#f0f0f0')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä TRAINING SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"‚úì Training completed after {len(epochs)} epochs\")\n",
    "    print(f\"‚úì Best model at epoch {best_epoch + 1}\")\n",
    "    print(f\"\\nüìà Best Metrics:\")\n",
    "    print(f\"  ‚Ä¢ Validation Loss: {min(history['val_losses']):.4f}\")\n",
    "    print(f\"  ‚Ä¢ Validation Accuracy: {max(history['val_accuracy']):.2%}\")\n",
    "    print(f\"\\nüìâ Final Metrics:\")\n",
    "    print(f\"  ‚Ä¢ Train Loss: {history['train_losses'][-1]:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Val Loss: {history['val_losses'][-1]:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Val Accuracy: {history['val_accuracy'][-1]:.2%}\")\n",
    "else:\n",
    "    print(\"‚ùå Training history not found at checkpoints/training_history.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41614a84",
   "metadata": {},
   "source": [
    "## Step 8: Continue Training from Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6e0603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/volodymyr/VS code/My_projecs/Pythons/Sound2Sheet/src/model/trainer.py:97: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = GradScaler() if training_config.use_mixed_precision else None\n",
      "/home/volodymyr/VS code/My_projecs/Pythons/Sound2Sheet/.venv/lib/python3.12/site-packages/torch/cuda/amp/grad_scaler.py:31: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting continued training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s]/home/volodymyr/VS code/My_projecs/Pythons/Sound2Sheet/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/volodymyr/VS code/My_projecs/Pythons/Sound2Sheet/src/model/trainer.py:251: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/volodymyr/VS code/My_projecs/Pythons/Sound2Sheet/.venv/lib/python3.12/site-packages/torch/amp/autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.12s/it, loss=4.69]\n",
      "Validation: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continued training complete!\n"
     ]
    }
   ],
   "source": [
    "# Load best model and continue training\n",
    "checkpoint = torch.load(f'data/{EXPERIMENT_NAME}/checkpoints/best_model.pt', map_location=device, weights_only=False)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# New config for continued training\n",
    "CONTINUE_EPOCHS = 30\n",
    "NEW_LR = 5e-5\n",
    "\n",
    "continued_config = TrainingConfig(\n",
    "    learning_rate=NEW_LR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_epochs=CONTINUE_EPOCHS,\n",
    "    optimizer='adamw',\n",
    "    scheduler='cosine',\n",
    "    use_mixed_precision=True,\n",
    "    max_grad_norm=1.0,\n",
    "    gradient_accumulation_steps=1,\n",
    "    checkpoint_dir=f'data/{EXPERIMENT_NAME}/checkpoints',\n",
    "    save_every_n_epochs=10,\n",
    "    early_stopping_patience=20\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer = Trainer(model, train_loader, val_loader, model_config, continued_config)\n",
    "print(\"Starting continued training...\")\n",
    "trainer.train()\n",
    "print(\"Continued training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
